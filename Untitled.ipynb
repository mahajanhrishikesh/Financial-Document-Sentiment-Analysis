{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MoneyControl-First-1-20-Pages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {2: 1, 1: 1, 0: 0, -1: -1, -2: -1}\n",
    "df.Label = [maps[i] for i in df.Label]\n",
    "df = df[df.Label != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>Label</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>article_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>April 13, 2020 12:04 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Max Financial gains 5% on Max Life extending i...</td>\n",
       "      <td>Max Financial Services share price rallied 4.7...</td>\n",
       "      <td>Max Life-Yes Bank relationship has over the ye...</td>\n",
       "      <td>Max Financial Services share price rallied 4.7...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>April 13, 2020 02:34 PM IST</td>\n",
       "      <td>-1</td>\n",
       "      <td>Nishant Kumar</td>\n",
       "      <td>Zee Entertainment share price plunges 14%, loo...</td>\n",
       "      <td>Zee Entertainment share price plunged over 14 ...</td>\n",
       "      <td>The company will extend financial and operatio...</td>\n",
       "      <td>Zee Entertainment share price plunged over 14 ...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>April 13, 2020 11:45 AM IST</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Bandhan Bank share price slips 10% despite str...</td>\n",
       "      <td>Bandhan Bank share price fell nearly 10 percen...</td>\n",
       "      <td>The capital adequacy ratio of the bank at the ...</td>\n",
       "      <td>Bandhan Bank share price fell nearly 10 percen...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>April 13, 2020 12:07 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandip Das</td>\n",
       "      <td>Cadila Healthcare shares rise 2% on USFDA nod ...</td>\n",
       "      <td>Share price of Cadila Healthcare was up over 2...</td>\n",
       "      <td>Zydus Cadila has received tentative approval f...</td>\n",
       "      <td>Share price of Cadila Healthcare was up over 2...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>April 13, 2020 01:33 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Indoco Remedies surges 16% as it ships Paracet...</td>\n",
       "      <td>Shares of Indoco Remedies rallied nearly 16 pe...</td>\n",
       "      <td>The permission granted by the Indian Governmen...</td>\n",
       "      <td>Shares of Indoco Remedies rallied nearly 16 pe...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         time  Label         author  \\\n",
       "0           0  April 13, 2020 12:04 PM IST      1   Sunil Matkar   \n",
       "3           3  April 13, 2020 02:34 PM IST     -1  Nishant Kumar   \n",
       "4           4  April 13, 2020 11:45 AM IST     -1   Sunil Matkar   \n",
       "5           5  April 13, 2020 12:07 PM IST      1     Sandip Das   \n",
       "8           8  April 13, 2020 01:33 PM IST      1   Sunil Matkar   \n",
       "\n",
       "                                               title  \\\n",
       "0  Max Financial gains 5% on Max Life extending i...   \n",
       "3  Zee Entertainment share price plunges 14%, loo...   \n",
       "4  Bandhan Bank share price slips 10% despite str...   \n",
       "5  Cadila Healthcare shares rise 2% on USFDA nod ...   \n",
       "8  Indoco Remedies surges 16% as it ships Paracet...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Max Financial Services share price rallied 4.7...   \n",
       "3  Zee Entertainment share price plunged over 14 ...   \n",
       "4  Bandhan Bank share price fell nearly 10 percen...   \n",
       "5  Share price of Cadila Healthcare was up over 2...   \n",
       "8  Shares of Indoco Remedies rallied nearly 16 pe...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Max Life-Yes Bank relationship has over the ye...   \n",
       "3  The company will extend financial and operatio...   \n",
       "4  The capital adequacy ratio of the bank at the ...   \n",
       "5  Zydus Cadila has received tentative approval f...   \n",
       "8  The permission granted by the Indian Governmen...   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  Max Financial Services share price rallied 4.7...   \n",
       "3  Zee Entertainment share price plunged over 14 ...   \n",
       "4  Bandhan Bank share price fell nearly 10 percen...   \n",
       "5  Share price of Cadila Healthcare was up over 2...   \n",
       "8  Shares of Indoco Remedies rallied nearly 16 pe...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.moneycontrol.com/news/business/mar...  \n",
       "3  https://www.moneycontrol.com/news/business/mar...  \n",
       "4  https://www.moneycontrol.com/news/business/mar...  \n",
       "5  https://www.moneycontrol.com/news/business/sto...  \n",
       "8  https://www.moneycontrol.com/news/business/mar...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
    "\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "def separate_punc(doc_text):\n",
    "    pre =  [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\r\\n\\r\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
    "    return [i for i in pre if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [separate_punc(i) for i in df.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokens)\n",
    "sequences = tokenizer.texts_to_sequences(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_article_length = max([len(i) for i in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_article_length, padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_article_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 18, 100)           134400    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 176,705\n",
      "Trainable params: 176,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 366 samples, validate on 41 samples\n",
      "Epoch 1/100\n",
      "366/366 [==============================] - 4s 10ms/step - loss: 2.8567 - acc: 0.0000e+00 - val_loss: 0.2639 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.5092 - acc: 0.0000e+00 - val_loss: 0.2210 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -0.2947 - acc: 0.0137 - val_loss: -1.1000 - val_acc: 0.2195\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -4.1997 - acc: 0.6148 - val_loss: -2.5391 - val_acc: 0.3659\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.1904 - acc: 0.7568 - val_loss: -2.7664 - val_acc: 0.5854\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.4345 - acc: 0.8525 - val_loss: -1.8415 - val_acc: 0.5854\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.6086 - acc: 0.8552 - val_loss: -1.4414 - val_acc: 0.5366\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.8586 - acc: 0.8825 - val_loss: -2.1853 - val_acc: 0.6098\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9376 - acc: 0.9126 - val_loss: -1.2016 - val_acc: 0.6341\n",
      "Epoch 10/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9478 - acc: 0.9344 - val_loss: -1.4010 - val_acc: 0.6341\n",
      "Epoch 11/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9438 - acc: 0.9426 - val_loss: -1.6822 - val_acc: 0.6585\n",
      "Epoch 12/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9426 - val_loss: -1.5597 - val_acc: 0.6585\n",
      "Epoch 13/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9485 - acc: 0.9344 - val_loss: -2.5278 - val_acc: 0.6585\n",
      "Epoch 14/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9887 - acc: 0.9481 - val_loss: -1.8266 - val_acc: 0.6341\n",
      "Epoch 15/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9555 - acc: 0.9508 - val_loss: -2.3579 - val_acc: 0.6829\n",
      "Epoch 16/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9511 - acc: 0.9508 - val_loss: -2.1977 - val_acc: 0.6585\n",
      "Epoch 17/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9887 - acc: 0.9563 - val_loss: -1.9896 - val_acc: 0.6829\n",
      "Epoch 18/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9891 - acc: 0.9536 - val_loss: -1.8781 - val_acc: 0.6829\n",
      "Epoch 19/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -1.7840 - val_acc: 0.6829\n",
      "Epoch 20/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9532 - acc: 0.9536 - val_loss: -2.6105 - val_acc: 0.6341\n",
      "Epoch 21/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9890 - acc: 0.9508 - val_loss: -1.8167 - val_acc: 0.6585\n",
      "Epoch 22/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.9347 - val_acc: 0.6829\n",
      "Epoch 23/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -1.8342 - val_acc: 0.6829\n",
      "Epoch 24/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9513 - acc: 0.9426 - val_loss: -1.8246 - val_acc: 0.6341\n",
      "Epoch 25/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9891 - acc: 0.9617 - val_loss: -1.8995 - val_acc: 0.6585\n",
      "Epoch 26/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.7912 - val_acc: 0.6585\n",
      "Epoch 27/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.3530 - val_acc: 0.6829\n",
      "Epoch 28/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.1907 - val_acc: 0.6829\n",
      "Epoch 29/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.3200 - val_acc: 0.6829\n",
      "Epoch 30/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.2836 - val_acc: 0.6829\n",
      "Epoch 31/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -1.0558 - val_acc: 0.6829\n",
      "Epoch 32/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9475 - acc: 0.9372 - val_loss: -1.7685 - val_acc: 0.6585\n",
      "Epoch 33/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.4080 - val_acc: 0.6585\n",
      "Epoch 34/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.2977 - val_acc: 0.6585\n",
      "Epoch 35/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.1818 - val_acc: 0.6585\n",
      "Epoch 36/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.0668 - val_acc: 0.6585\n",
      "Epoch 37/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9481 - val_loss: -1.2716 - val_acc: 0.6829\n",
      "Epoch 38/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9426 - val_loss: -1.1184 - val_acc: 0.6829\n",
      "Epoch 39/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9317 - val_loss: -0.8576 - val_acc: 0.7073\n",
      "Epoch 40/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9525 - acc: 0.9426 - val_loss: -1.1877 - val_acc: 0.6585\n",
      "Epoch 41/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.1328 - val_acc: 0.6585\n",
      "Epoch 42/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.0558 - val_acc: 0.6585\n",
      "Epoch 43/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -0.9980 - val_acc: 0.6585\n",
      "Epoch 44/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9481 - val_loss: -0.9016 - val_acc: 0.6585\n",
      "Epoch 45/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9481 - val_loss: -0.7860 - val_acc: 0.6829\n",
      "Epoch 46/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9426 - val_loss: -0.6055 - val_acc: 0.6829\n",
      "Epoch 47/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9372 - val_loss: -0.7621 - val_acc: 0.6829\n",
      "Epoch 48/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9528 - acc: 0.9481 - val_loss: -1.3266 - val_acc: 0.6585\n",
      "Epoch 49/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.2231 - val_acc: 0.6585\n",
      "Epoch 50/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.1556 - val_acc: 0.6585\n",
      "Epoch 51/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.0918 - val_acc: 0.6585\n",
      "Epoch 52/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9508 - val_loss: -1.0112 - val_acc: 0.6585\n",
      "Epoch 53/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -0.8686 - val_acc: 0.6829\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9528 - acc: 0.9481 - val_loss: -1.5606 - val_acc: 0.6585\n",
      "Epoch 55/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.4105 - val_acc: 0.6585\n",
      "Epoch 56/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.3106 - val_acc: 0.6585\n",
      "Epoch 57/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.2229 - val_acc: 0.6341\n",
      "Epoch 58/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.1352 - val_acc: 0.6341\n",
      "Epoch 59/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.0083 - val_acc: 0.6585\n",
      "Epoch 60/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.1879 - val_acc: 0.6585\n",
      "Epoch 61/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.4633 - val_acc: 0.6585\n",
      "Epoch 62/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9495 - acc: 0.9536 - val_loss: -0.9747 - val_acc: 0.6585\n",
      "Epoch 63/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.1946 - val_acc: 0.6585\n",
      "Epoch 64/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.1500 - val_acc: 0.6585\n",
      "Epoch 65/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.0904 - val_acc: 0.6585\n",
      "Epoch 66/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -0.9844 - val_acc: 0.6585\n",
      "Epoch 67/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -0.8954 - val_acc: 0.6585\n",
      "Epoch 68/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.0577 - val_acc: 0.6585\n",
      "Epoch 69/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.3586 - val_acc: 0.6585\n",
      "Epoch 70/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9508 - val_loss: -0.8032 - val_acc: 0.7073\n",
      "Epoch 71/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9482 - acc: 0.9563 - val_loss: -1.3885 - val_acc: 0.6585\n",
      "Epoch 72/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.3263 - val_acc: 0.6585\n",
      "Epoch 73/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.2481 - val_acc: 0.6829\n",
      "Epoch 74/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.1429 - val_acc: 0.6585\n",
      "Epoch 75/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.0463 - val_acc: 0.6585\n",
      "Epoch 76/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.5792 - val_acc: 0.6585\n",
      "Epoch 77/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.1402 - val_acc: 0.6585\n",
      "Epoch 78/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -0.9670 - val_acc: 0.6829\n",
      "Epoch 79/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9559 - acc: 0.9563 - val_loss: -1.4277 - val_acc: 0.6585\n",
      "Epoch 80/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.3452 - val_acc: 0.6585\n",
      "Epoch 81/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.3028 - val_acc: 0.6585\n",
      "Epoch 82/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9617 - val_loss: -1.2316 - val_acc: 0.6585\n",
      "Epoch 83/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.1679 - val_acc: 0.6585\n",
      "Epoch 84/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.0799 - val_acc: 0.6829\n",
      "Epoch 85/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9536 - val_loss: -1.3141 - val_acc: 0.6585\n",
      "Epoch 86/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -1.2274 - val_acc: 0.6585\n",
      "Epoch 87/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9462 - acc: 0.9508 - val_loss: -1.5272 - val_acc: 0.6585\n",
      "Epoch 88/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9891 - acc: 0.9563 - val_loss: -1.2893 - val_acc: 0.6829\n",
      "Epoch 89/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.2024 - val_acc: 0.6829\n",
      "Epoch 90/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.0963 - val_acc: 0.6829\n",
      "Epoch 91/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9508 - val_loss: -1.2711 - val_acc: 0.6341\n",
      "Epoch 92/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9454 - val_loss: -1.2205 - val_acc: 0.6341\n",
      "Epoch 93/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9399 - val_loss: -1.0626 - val_acc: 0.6341\n",
      "Epoch 94/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9582 - acc: 0.9399 - val_loss: -1.3413 - val_acc: 0.6829\n",
      "Epoch 95/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.2186 - val_acc: 0.6829\n",
      "Epoch 96/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -1.1243 - val_acc: 0.6829\n",
      "Epoch 97/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9590 - val_loss: -1.0527 - val_acc: 0.6829\n",
      "Epoch 98/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9563 - val_loss: -0.9746 - val_acc: 0.6829\n",
      "Epoch 99/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9481 - val_loss: -0.8572 - val_acc: 0.6829\n",
      "Epoch 100/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: -5.9892 - acc: 0.9508 - val_loss: -0.7635 - val_acc: 0.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9b2f9e888>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_article_length))\n",
    "#model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=100, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1343\n"
     ]
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(tokens, size=100, window=5, workers=8, min_count=1)\n",
    "# summarize vocabulary size in model\n",
    "words = list(model.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(words))\n",
    " \n",
    "# save model in ASCII (word2vec) format\n",
    "filename = 'embedding_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "\t# load embedding into memory, skip first line\n",
    "\tfile = open(filename,'r')\n",
    "\tlines = file.readlines()[1:]\n",
    "\tfile.close()\n",
    "\t# create a map of words to vectors\n",
    "\tembedding = dict()\n",
    "\tfor line in lines:\n",
    "\t\tparts = line.split()\n",
    "\t\t# key is string word, value is numpy array for vector\n",
    "\t\tembedding[parts[0]] = np.array(parts[1:], dtype='float32')\n",
    "\treturn embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "\t# total vocabulary size plus 0 for unknown words\n",
    "\tvocab_size = len(vocab) + 1\n",
    "\t# define weight matrix dimensions with all 0\n",
    "\tweight_matrix = np.zeros((vocab_size, 100))\n",
    "\t# step vocab, store vectors using the Tokenizer's integer mapping\n",
    "\tfor word, i in vocab.items():\n",
    "\t\tweight_matrix[i] = embedding.get(word)\n",
    "\treturn weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding from file\n",
    "raw_embedding = load_embedding('embedding_word2vec.txt')\n",
    "# get vectors in the right order\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "# create the embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 18, 100)           134400    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 176,705\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 134,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 366 samples, validate on 41 samples\n",
      "Epoch 1/100\n",
      "366/366 [==============================] - 4s 11ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "366/366 [==============================] - 1s 2ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " 96/366 [======>.......................] - ETA: 0s - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-d2085114badb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adadelta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='mean_squared_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=100, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
