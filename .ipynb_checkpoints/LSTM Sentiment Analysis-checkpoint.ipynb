{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "d1 = pd.read_csv('MoneyControl-First-1-10-Pages.csv')\n",
    "d2 = pd.read_csv('MoneyControl-First-11-20-Pages.csv')\n",
    "d3 = pd.read_csv('MoneyControl-First-1-10-Pages-New.csv')\n",
    "df = pd.concat([d1,d2,d3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\")) \n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "def preprocessor(line):\n",
    "    line = line.lower()\n",
    "    line = line.split()\n",
    "    #print(line)\n",
    "    line = [stemming.stem(i) for i in line]\n",
    "    #print(line)\n",
    "    line = [i for i in line if not i in stops]\n",
    "    #print(line)\n",
    "    return ' '.join(line)\n",
    "df.title = [preprocessor(i) for i in df.title]\n",
    "df.summary = [preprocessor(i) for i in df.summary]\n",
    "df.article_text = [preprocessor(i) for i in df.article_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'max financi servic share price ralli 4.7 percent intraday april 13 insur subsidiari extend five-year bancassur partnership privat sector lender ye bank. wa trade rs 363.75, rs 11.70, 3.32 percent, bse 1138 hours. \"max life insur ye bank announc five-year extens strateg bancassur relationship. compani began partnership februari 2005, core commit toward secur financi futur customers. partnership ha settl death claim rs 70 crore, offer protect worth around rs 34,500 crore policyhold families.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {2: 1, 1: 1, 0: 0, -1: -1, -2: -1}\n",
    "df.Label = [maps[i] for i in df.Label]\n",
    "df = df[df.Label != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>Label</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>article_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>April 13, 2020 12:04 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Max Financial gains 5% on Max Life extending i...</td>\n",
       "      <td>Max Financial Services share price rallied 4.7...</td>\n",
       "      <td>Max Life-Yes Bank relationship has over the ye...</td>\n",
       "      <td>Max Financial Services share price rallied 4.7...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>April 13, 2020 02:34 PM IST</td>\n",
       "      <td>-1</td>\n",
       "      <td>Nishant Kumar</td>\n",
       "      <td>Zee Entertainment share price plunges 14%, loo...</td>\n",
       "      <td>Zee Entertainment share price plunged over 14 ...</td>\n",
       "      <td>The company will extend financial and operatio...</td>\n",
       "      <td>Zee Entertainment share price plunged over 14 ...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>April 13, 2020 11:45 AM IST</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Bandhan Bank share price slips 10% despite str...</td>\n",
       "      <td>Bandhan Bank share price fell nearly 10 percen...</td>\n",
       "      <td>The capital adequacy ratio of the bank at the ...</td>\n",
       "      <td>Bandhan Bank share price fell nearly 10 percen...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>April 13, 2020 12:07 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandip Das</td>\n",
       "      <td>Cadila Healthcare shares rise 2% on USFDA nod ...</td>\n",
       "      <td>Share price of Cadila Healthcare was up over 2...</td>\n",
       "      <td>Zydus Cadila has received tentative approval f...</td>\n",
       "      <td>Share price of Cadila Healthcare was up over 2...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>April 13, 2020 01:33 PM IST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunil Matkar</td>\n",
       "      <td>Indoco Remedies surges 16% as it ships Paracet...</td>\n",
       "      <td>Shares of Indoco Remedies rallied nearly 16 pe...</td>\n",
       "      <td>The permission granted by the Indian Governmen...</td>\n",
       "      <td>Shares of Indoco Remedies rallied nearly 16 pe...</td>\n",
       "      <td>https://www.moneycontrol.com/news/business/mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         time  Label         author  \\\n",
       "0           0  April 13, 2020 12:04 PM IST      1   Sunil Matkar   \n",
       "3           3  April 13, 2020 02:34 PM IST     -1  Nishant Kumar   \n",
       "4           4  April 13, 2020 11:45 AM IST     -1   Sunil Matkar   \n",
       "5           5  April 13, 2020 12:07 PM IST      1     Sandip Das   \n",
       "8           8  April 13, 2020 01:33 PM IST      1   Sunil Matkar   \n",
       "\n",
       "                                               title  \\\n",
       "0  Max Financial gains 5% on Max Life extending i...   \n",
       "3  Zee Entertainment share price plunges 14%, loo...   \n",
       "4  Bandhan Bank share price slips 10% despite str...   \n",
       "5  Cadila Healthcare shares rise 2% on USFDA nod ...   \n",
       "8  Indoco Remedies surges 16% as it ships Paracet...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Max Financial Services share price rallied 4.7...   \n",
       "3  Zee Entertainment share price plunged over 14 ...   \n",
       "4  Bandhan Bank share price fell nearly 10 percen...   \n",
       "5  Share price of Cadila Healthcare was up over 2...   \n",
       "8  Shares of Indoco Remedies rallied nearly 16 pe...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Max Life-Yes Bank relationship has over the ye...   \n",
       "3  The company will extend financial and operatio...   \n",
       "4  The capital adequacy ratio of the bank at the ...   \n",
       "5  Zydus Cadila has received tentative approval f...   \n",
       "8  The permission granted by the Indian Governmen...   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  Max Financial Services share price rallied 4.7...   \n",
       "3  Zee Entertainment share price plunged over 14 ...   \n",
       "4  Bandhan Bank share price fell nearly 10 percen...   \n",
       "5  Share price of Cadila Healthcare was up over 2...   \n",
       "8  Shares of Indoco Remedies rallied nearly 16 pe...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.moneycontrol.com/news/business/mar...  \n",
       "3  https://www.moneycontrol.com/news/business/mar...  \n",
       "4  https://www.moneycontrol.com/news/business/mar...  \n",
       "5  https://www.moneycontrol.com/news/business/sto...  \n",
       "8  https://www.moneycontrol.com/news/business/mar...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
    "\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "def separate_punc(doc_text):\n",
    "    pre =  [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\r\\n\\r\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
    "    return [i for i in pre if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [separate_punc(i) for i in df.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokens)\n",
    "sequences = tokenizer.texts_to_sequences(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_article_length = max([len(i) for i in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = {-2: 'VN', -1:'N', 0:'Ne', 1:'P', 2:'VP'}\n",
    "df['Label_text'] = [name[i] for i in df['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_article_length, padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_article_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([262,   2, 310,  72, 421, 568, 569,  76, 570, 229, 320,  65,   5,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "E:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc_y = MinMaxScaler()\n",
    "y_train = sc_y.fit_transform(y_train.values.reshape(-1,1))\n",
    "sc_yt = MinMaxScaler()\n",
    "y_test = sc_yt.fit_transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 18, 50)            83400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 112,905\n",
      "Trainable params: 112,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 585 samples, validate on 66 samples\n",
      "Epoch 1/50\n",
      "585/585 [==============================] - 6s 11ms/step - loss: 0.9143 - acc: 0.2581 - val_loss: 0.6697 - val_acc: 0.3030\n",
      "Epoch 2/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.6079 - acc: 0.3744 - val_loss: 0.9197 - val_acc: 0.3030\n",
      "Epoch 3/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.5340 - acc: 0.4342 - val_loss: 0.6038 - val_acc: 0.3636\n",
      "Epoch 4/50\n",
      "585/585 [==============================] - 2s 4ms/step - loss: 0.4876 - acc: 0.4564 - val_loss: 0.5552 - val_acc: 0.3939\n",
      "Epoch 5/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.4737 - acc: 0.4650 - val_loss: 1.0631 - val_acc: 0.4394\n",
      "Epoch 6/50\n",
      "585/585 [==============================] - 2s 4ms/step - loss: 0.4493 - acc: 0.4701 - val_loss: 1.0100 - val_acc: 0.4242\n",
      "Epoch 7/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.4435 - acc: 0.4701 - val_loss: 0.7165 - val_acc: 0.3485\n",
      "Epoch 8/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.4118 - acc: 0.4701 - val_loss: 0.7755 - val_acc: 0.3788\n",
      "Epoch 9/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.4137 - acc: 0.4718 - val_loss: 0.9012 - val_acc: 0.4545\n",
      "Epoch 10/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3999 - acc: 0.4735 - val_loss: 0.7878 - val_acc: 0.4242\n",
      "Epoch 11/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3897 - acc: 0.4786 - val_loss: 0.7935 - val_acc: 0.4394\n",
      "Epoch 12/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3905 - acc: 0.4752 - val_loss: 0.7826 - val_acc: 0.4394\n",
      "Epoch 13/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3822 - acc: 0.4786 - val_loss: 0.7601 - val_acc: 0.4545\n",
      "Epoch 14/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3812 - acc: 0.4803 - val_loss: 0.7400 - val_acc: 0.3485\n",
      "Epoch 15/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3759 - acc: 0.4786 - val_loss: 0.5250 - val_acc: 0.3939\n",
      "Epoch 16/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3678 - acc: 0.4786 - val_loss: 0.7807 - val_acc: 0.4394\n",
      "Epoch 17/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3587 - acc: 0.4803 - val_loss: 0.7444 - val_acc: 0.4394\n",
      "Epoch 18/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3587 - acc: 0.4786 - val_loss: 0.7703 - val_acc: 0.4697\n",
      "Epoch 19/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3566 - acc: 0.4786 - val_loss: 0.7710 - val_acc: 0.4242\n",
      "Epoch 20/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3554 - acc: 0.4786 - val_loss: 0.7643 - val_acc: 0.4394\n",
      "Epoch 21/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3501 - acc: 0.4803 - val_loss: 0.7500 - val_acc: 0.4545\n",
      "Epoch 22/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3582 - acc: 0.4786 - val_loss: 0.9203 - val_acc: 0.3788\n",
      "Epoch 23/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3504 - acc: 0.4803 - val_loss: 0.7515 - val_acc: 0.4242\n",
      "Epoch 24/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3562 - acc: 0.4803 - val_loss: 0.7973 - val_acc: 0.4545\n",
      "Epoch 25/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3497 - acc: 0.4803 - val_loss: 0.7931 - val_acc: 0.4545\n",
      "Epoch 26/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3492 - acc: 0.4803 - val_loss: 0.7974 - val_acc: 0.4394\n",
      "Epoch 27/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3536 - acc: 0.4803 - val_loss: 0.7451 - val_acc: 0.4394\n",
      "Epoch 28/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3439 - acc: 0.4803 - val_loss: 0.7673 - val_acc: 0.4697\n",
      "Epoch 29/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3495 - acc: 0.4803 - val_loss: 0.7813 - val_acc: 0.4545\n",
      "Epoch 30/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3502 - acc: 0.4803 - val_loss: 0.7686 - val_acc: 0.4545\n",
      "Epoch 31/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3541 - acc: 0.4803 - val_loss: 0.9032 - val_acc: 0.4545\n",
      "Epoch 32/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3449 - acc: 0.4803 - val_loss: 0.8216 - val_acc: 0.4545\n",
      "Epoch 33/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3460 - acc: 0.4803 - val_loss: 0.7910 - val_acc: 0.4545\n",
      "Epoch 34/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3412 - acc: 0.4803 - val_loss: 0.5743 - val_acc: 0.4394\n",
      "Epoch 35/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3430 - acc: 0.4803 - val_loss: 0.8138 - val_acc: 0.4394\n",
      "Epoch 36/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3453 - acc: 0.4803 - val_loss: 0.7899 - val_acc: 0.4545\n",
      "Epoch 37/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3435 - acc: 0.4803 - val_loss: 0.8014 - val_acc: 0.4697\n",
      "Epoch 38/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3468 - acc: 0.4803 - val_loss: 0.7431 - val_acc: 0.4697\n",
      "Epoch 39/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3464 - acc: 0.4803 - val_loss: 0.7455 - val_acc: 0.4848s: 0.3441 - ac\n",
      "Epoch 40/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3475 - acc: 0.4803 - val_loss: 0.8144 - val_acc: 0.4697\n",
      "Epoch 41/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3498 - acc: 0.4803 - val_loss: 0.9001 - val_acc: 0.4242\n",
      "Epoch 42/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3457 - acc: 0.4803 - val_loss: 0.8184 - val_acc: 0.4394\n",
      "Epoch 43/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3471 - acc: 0.4803 - val_loss: 0.7974 - val_acc: 0.4697\n",
      "Epoch 44/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3392 - acc: 0.4803 - val_loss: 0.8013 - val_acc: 0.4697\n",
      "Epoch 45/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3415 - acc: 0.4803 - val_loss: 0.7583 - val_acc: 0.4697\n",
      "Epoch 46/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3378 - acc: 0.4803 - val_loss: 0.7535 - val_acc: 0.4697\n",
      "Epoch 47/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3376 - acc: 0.4803 - val_loss: 0.7884 - val_acc: 0.4697\n",
      "Epoch 48/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3427 - acc: 0.4803 - val_loss: 0.7435 - val_acc: 0.4697\n",
      "Epoch 49/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3352 - acc: 0.4803 - val_loss: 0.7453 - val_acc: 0.4697\n",
      "Epoch 50/50\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.3383 - acc: 0.4803 - val_loss: 0.7771 - val_acc: 0.4545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260c8fc0788>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector_length = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(1668, embedding_vector_length, input_length=max_article_length))\n",
    "model.add(LSTM(64))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.73%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177, 268, 256,   3, 893,  36, 126, 687,   6,  81,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text(line):\n",
    "    dummy_list =list()\n",
    "    line_tokens = separate_punc(line)\n",
    "    dummy_list.append(line_tokens)\n",
    "    line_sequence = tokenizer.texts_to_sequences(dummy_list)\n",
    "    while len(line_sequence[0])!= max_article_length:\n",
    "        line_sequence[0].append(0)\n",
    "    final = np.array(line_sequence[0])\n",
    "    final = final.reshape(18,)\n",
    "    return final\n",
    "text(\"Small & Mid-cap party! More than 130 stocks in S&P BSE 500 index rose 10-40%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9524079]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Small & Mid-cap party! More than 130 stocks in S&P BSE 500 index rose 10-40%\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.92960757]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Sensex down by 3000 points\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99866396]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Kotak Securities suggests buy on Tata Motors\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5889105]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Kotak Securities suggests sell on Tata Motors\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999934]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Pharma stocks surge. Cipla jumps by 9%\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77424985]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"Pharma stocks fall. Cipla falls by 9%\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5422711]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"S&P Slashes India's Growth Forecast For FY21 To 1.8%\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.906007]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = text(\"China Reports First Quarterly GDP Shrinkage In Decades Due To COVID-19\")\n",
    "pred_list = list()\n",
    "pred_list.append(x)\n",
    "pred_list = np.array(pred_list)\n",
    "model.predict(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list()\n",
    "for i in predictions:\n",
    "    if i < 0:\n",
    "        preds.append(-1)\n",
    "    else:\n",
    "        preds.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  6],\n",
       "       [ 4, 16]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7560975609756098"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 18, 50)            67200     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 96,705\n",
      "Trainable params: 96,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 366 samples, validate on 41 samples\n",
      "Epoch 1/150\n",
      "366/366 [==============================] - 17s 46ms/step - loss: 2.5785 - acc: 0.0000e+00 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 0.5227 - acc: 0.0000e+00 - val_loss: 0.2261 - val_acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 0.4310 - acc: 0.0000e+00 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -2.7115 - acc: 0.2951 - val_loss: -2.8317 - val_acc: 0.3415\n",
      "Epoch 5/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -4.9949 - acc: 0.6749 - val_loss: -2.2461 - val_acc: 0.6341\n",
      "Epoch 6/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.1045 - acc: 0.7896 - val_loss: -3.1768 - val_acc: 0.5122\n",
      "Epoch 7/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.6313 - acc: 0.8224 - val_loss: -2.6659 - val_acc: 0.5366\n",
      "Epoch 8/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -5.7529 - acc: 0.8716 - val_loss: -2.4797 - val_acc: 0.5610\n",
      "Epoch 9/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -5.7638 - acc: 0.8907 - val_loss: -1.9324 - val_acc: 0.6098\n",
      "Epoch 10/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -5.8138 - acc: 0.8907 - val_loss: -2.1250 - val_acc: 0.6829\n",
      "Epoch 11/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8231 - acc: 0.9180 - val_loss: -2.5579 - val_acc: 0.6585\n",
      "Epoch 12/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8563 - acc: 0.9426 - val_loss: -2.3604 - val_acc: 0.6829\n",
      "Epoch 13/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8570 - acc: 0.9344 - val_loss: -1.9219 - val_acc: 0.6829\n",
      "Epoch 14/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8132 - acc: 0.9317 - val_loss: -1.2879 - val_acc: 0.6585\n",
      "Epoch 15/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8626 - acc: 0.9262 - val_loss: -1.6240 - val_acc: 0.6585\n",
      "Epoch 16/150\n",
      "366/366 [==============================] - 2s 4ms/step - loss: -5.8589 - acc: 0.9208 - val_loss: -2.1180 - val_acc: 0.6585\n",
      "Epoch 17/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8239 - acc: 0.9399 - val_loss: -2.5566 - val_acc: 0.6829\n",
      "Epoch 18/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8570 - acc: 0.9317 - val_loss: -2.1395 - val_acc: 0.6829\n",
      "Epoch 19/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8241 - acc: 0.9454 - val_loss: -2.5909 - val_acc: 0.6585\n",
      "Epoch 20/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8569 - acc: 0.9399 - val_loss: -2.4293 - val_acc: 0.6585\n",
      "Epoch 21/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8157 - acc: 0.9426 - val_loss: -2.6168 - val_acc: 0.6341\n",
      "Epoch 22/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8562 - acc: 0.9454 - val_loss: -2.3745 - val_acc: 0.6341\n",
      "Epoch 23/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9454 - val_loss: -2.2794 - val_acc: 0.6341\n",
      "Epoch 24/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9426 - val_loss: -2.1863 - val_acc: 0.6585\n",
      "Epoch 25/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9399 - val_loss: -1.8442 - val_acc: 0.6585\n",
      "Epoch 26/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9426 - val_loss: -1.6185 - val_acc: 0.6585\n",
      "Epoch 27/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8172 - acc: 0.9290 - val_loss: -2.7745 - val_acc: 0.6585\n",
      "Epoch 28/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8569 - acc: 0.9508 - val_loss: -2.6118 - val_acc: 0.6585\n",
      "Epoch 29/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9508 - val_loss: -2.5541 - val_acc: 0.6585\n",
      "Epoch 30/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8199 - acc: 0.9426 - val_loss: -2.3616 - val_acc: 0.6829\n",
      "Epoch 31/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8570 - acc: 0.9536 - val_loss: -2.1960 - val_acc: 0.7073\n",
      "Epoch 32/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9536 - val_loss: -2.1504 - val_acc: 0.7073\n",
      "Epoch 33/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9536 - val_loss: -2.3823 - val_acc: 0.6829\n",
      "Epoch 34/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9536 - val_loss: -2.3732 - val_acc: 0.6829\n",
      "Epoch 35/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9536 - val_loss: -2.0327 - val_acc: 0.6341\n",
      "Epoch 36/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9508 - val_loss: -1.9475 - val_acc: 0.6341\n",
      "Epoch 37/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -1.8581 - val_acc: 0.6585\n",
      "Epoch 38/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9344 - val_loss: -1.4508 - val_acc: 0.6585\n",
      "Epoch 39/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8186 - acc: 0.9153 - val_loss: -1.5053 - val_acc: 0.6585\n",
      "Epoch 40/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8621 - acc: 0.9180 - val_loss: -2.5415 - val_acc: 0.6585\n",
      "Epoch 41/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -2.5210 - val_acc: 0.6585\n",
      "Epoch 42/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -2.1693 - val_acc: 0.6585\n",
      "Epoch 43/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -2.1115 - val_acc: 0.6585\n",
      "Epoch 44/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -2.0634 - val_acc: 0.6585\n",
      "Epoch 45/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9481 - val_loss: -2.0060 - val_acc: 0.6341\n",
      "Epoch 46/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9344 - val_loss: -1.9184 - val_acc: 0.6585\n",
      "Epoch 47/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9262 - val_loss: -1.1294 - val_acc: 0.6585\n",
      "Epoch 48/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8346 - acc: 0.9180 - val_loss: -2.0685 - val_acc: 0.6585\n",
      "Epoch 49/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8656 - acc: 0.9290 - val_loss: -2.6749 - val_acc: 0.6585\n",
      "Epoch 50/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8570 - acc: 0.9426 - val_loss: -2.2322 - val_acc: 0.6585\n",
      "Epoch 51/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9372 - val_loss: -2.1808 - val_acc: 0.6585\n",
      "Epoch 52/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8571 - acc: 0.9317 - val_loss: -2.1150 - val_acc: 0.6585\n",
      "Epoch 53/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.7231 - acc: 0.9071 - val_loss: -1.5993 - val_acc: 0.6585\n",
      "Epoch 54/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.8242 - acc: 0.9180 - val_loss: -2.3116 - val_acc: 0.6585\n",
      "Epoch 55/150\n",
      "366/366 [==============================] - 1s 4ms/step - loss: -5.9004 - acc: 0.9426 - val_loss: -2.2389 - val_acc: 0.6829\n",
      "Epoch 56/150\n",
      "152/366 [===========>..................] - ETA: 0s - loss: -6.1503 - acc: 0.9539"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-7349da6a6b8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(1344, embedding_vector_length, input_length=max_article_length))\n",
    "model.add(LSTM(64))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
